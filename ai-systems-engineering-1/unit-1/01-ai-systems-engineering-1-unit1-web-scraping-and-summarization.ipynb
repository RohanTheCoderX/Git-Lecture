{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanTheCoderX/Git-Lecture/blob/main/ai-systems-engineering-1/unit-1/01-ai-systems-engineering-1-unit1-web-scraping-and-summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odQn8846ysnQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n",
        "\n",
        "## Unit 1: Web Scraping and Summarization with LLMs\n",
        "\n",
        "**CV Raman Global University, Bhubaneswar**  \n",
        "*AI Center of Excellence*\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "1. **Make your first OpenAI API call** and understand the Chat Completions API\n",
        "2. **Learn about system and user prompts** and how to structure messages\n",
        "3. **Build a web scraper** using BeautifulSoup to extract website content\n",
        "4. **Create a website summarizer** that generates concise summaries using GPT\n",
        "\n",
        "**Duration:** ~1.5 hours\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-1eOPQaysnR"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "Let's install the required packages and configure our API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFWgPOiGysnS"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q openai requests beautifulsoup4 1234rohan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37BSxiorysnS"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TietaTy2ysnS"
      },
      "outputs": [],
      "source": [
        "# Configure OpenAI API Key\n",
        "api_key = getpass(\"Enter your OpenAI API Key: \")\n",
        "\n",
        "if api_key and api_key.strip():\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    MODEL = \"gpt-4o-mini\"\n",
        "    print(f\"OpenAI configured with model: {MODEL}\")\n",
        "else:\n",
        "    print(\"No API key provided. Please enter your key to continue.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scnMXeBVysnS"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Your First API Call\n",
        "\n",
        "Let's start with a simple API call to understand how to communicate with GPT models.\n",
        "\n",
        "The OpenAI API expects messages in this structure:\n",
        "\n",
        "```python\n",
        "[\n",
        "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
        "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdWlsBj9ysnT"
      },
      "outputs": [],
      "source": [
        "# Simple API call\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hello! This is my first message to you.\"}]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0DbWdSLysnT"
      },
      "outputs": [],
      "source": [
        "# Using system and user prompts\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(model=MODEL, messages=messages)\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTE35-A4ysnT"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Web Scraping with BeautifulSoup\n",
        "\n",
        "Before we can summarize websites, we need to extract their content. We'll use BeautifulSoup to parse HTML and extract readable text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dfWDJ57ysnT"
      },
      "outputs": [],
      "source": [
        "# Web scraping utility functions\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "def fetch_website_contents(url, max_chars=2000):\n",
        "    \"\"\"\n",
        "    Fetch and return the title and text content of a website.\n",
        "    Removes scripts, styles, and other non-text elements.\n",
        "    \"\"\"\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    title = soup.title.string if soup.title else \"No title found\"\n",
        "\n",
        "    if soup.body:\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "    else:\n",
        "        text = \"\"\n",
        "\n",
        "    return (title + \"\\n\\n\" + text)[:max_chars]\n",
        "\n",
        "\n",
        "def fetch_website_links(url):\n",
        "    \"\"\"\n",
        "    Return all links found on a webpage.\n",
        "    \"\"\"\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
        "    return [link for link in links if link]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCkLloQgysnT"
      },
      "outputs": [],
      "source": [
        "# Test the scraper\n",
        "website_content = fetch_website_contents(\"https://anthropic.com\")\n",
        "print(website_content[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovkRCxc0ysnU"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Building the Website Summarizer\n",
        "\n",
        "Now let's combine web scraping with LLM capabilities to create a website summarizer.\n",
        "\n",
        "### Types of Prompts\n",
        "\n",
        "- **System Prompt**: Tells the model what task to perform and what tone to use\n",
        "- **User Prompt**: The actual content or question to respond to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImV98SRjysnU"
      },
      "outputs": [],
      "source": [
        "# Define prompts for summarization\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are an expert content analyst that analyzes website contents\n",
        "and provides concise, informative summaries.\n",
        "Ignore navigation-related text and focus on the main content.\n",
        "Respond in markdown format.\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT_PREFIX = \"\"\"\n",
        "Here are the contents of a website.\n",
        "Provide a clear summary of this website.\n",
        "If it includes news or announcements, summarize these too.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8b9mkmjysnU"
      },
      "outputs": [],
      "source": [
        "def create_messages(website_content):\n",
        "    \"\"\"Create the message structure for the API call.\"\"\"\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": USER_PROMPT_PREFIX + website_content}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNCTz6XuysnU"
      },
      "outputs": [],
      "source": [
        "def summarize_website(url):\n",
        "    \"\"\"Fetch a website and generate a summary using GPT.\"\"\"\n",
        "    website_content = fetch_website_contents(url)\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=create_messages(website_content)\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def display_summary(url):\n",
        "    \"\"\"Display a formatted summary of a website.\"\"\"\n",
        "    summary = summarize_website(url)\n",
        "    display(Markdown(summary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqHDc0RAysnU"
      },
      "outputs": [],
      "source": [
        "# Test the summarizer\n",
        "display_summary(\"https://anthropic.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wItf_eicysnU"
      },
      "outputs": [],
      "source": [
        "# Try another website\n",
        "display_summary(\"https://cnn.com\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZmBOlwTysnU"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Exercises\n",
        "\n",
        "### Exercise 1: Create an Email Subject Generator\n",
        "\n",
        "Create a function that takes email content and suggests an appropriate subject line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtESYJcbysnU"
      },
      "outputs": [],
      "source": [
        "# Exercise 1: Email Subject Generator\n",
        "# Step 1: Create your prompts\n",
        "\n",
        "email_system_prompt = \"\"  # Define the system prompt\n",
        "\n",
        "email_content = \"\"\"\n",
        "Hi Team,\n",
        "\n",
        "I wanted to follow up on our meeting yesterday about the Q4 targets.\n",
        "We discussed increasing sales by 15% and expanding into two new markets.\n",
        "Please review the attached proposal and share your feedback by Friday.\n",
        "\n",
        "Best regards,\n",
        "Manager\n",
        "\"\"\"\n",
        "\n",
        "# Step 2: Make the messages list and call OpenAI\n",
        "# messages = [...]\n",
        "# response = client.chat.completions.create(...)\n",
        "\n",
        "# Step 3: Print the result\n",
        "# print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_rD_QtqysnU"
      },
      "source": [
        "### Exercise 2: Summarize Multiple Websites\n",
        "\n",
        "Create a function that takes a list of URLs and returns summaries for all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8ydnEYTysnU"
      },
      "outputs": [],
      "source": [
        "# Exercise 2: Batch summarizer\n",
        "def summarize_multiple(urls):\n",
        "    \"\"\"Summarize multiple websites.\"\"\"\n",
        "    # Your implementation here\n",
        "    pass\n",
        "\n",
        "# Test with:\n",
        "# urls = [\"https://anthropic.com\", \"https://openai.com\"]\n",
        "# summarize_multiple(urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm7xqN9pysnU"
      },
      "source": [
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **OpenAI API** uses a simple message structure with roles: system, user, and assistant\n",
        "\n",
        "2. **System prompts** define the behavior and tone of the model\n",
        "\n",
        "3. **BeautifulSoup** is excellent for extracting text content from web pages\n",
        "\n",
        "4. **Summarization** is a powerful use case - applicable to news, documents, emails, and more\n",
        "\n",
        "### Limitations\n",
        "\n",
        "- JavaScript-rendered websites (React apps) won't work with basic scraping\n",
        "- Some websites block scrapers (CloudFlare protection)\n",
        "- Content is truncated to fit within context limits\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "In the next notebook, we'll explore:\n",
        "- Comparing different model providers (OpenAI, Gemini, Ollama)\n",
        "- Understanding HTTP endpoints vs client libraries\n",
        "- Running models locally\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "- [OpenAI Chat Completions API](https://platform.openai.com/docs/guides/text-generation)\n",
        "- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
        "\n",
        "---\n",
        "\n",
        "**Course Information:**\n",
        "- **Institution:** CV Raman Global University, Bhubaneswar\n",
        "- **Program:** AI Center of Excellence\n",
        "- **Course:** AI Systems Engineering 1\n",
        "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}